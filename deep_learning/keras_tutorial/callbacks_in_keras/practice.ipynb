{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db54ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,LearningRateScheduler,TensorBoard\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623ceb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c61843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirzar-diwan/miniconda3/lib/python3.13/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape = (28,28)),\n",
    "        Dense(128,activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(10,activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc9d0e",
   "metadata": {},
   "source": [
    "## Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26965bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_cb = ModelCheckpoint(\n",
    "    filepath = 'saved_models/model{epoch:02d}.keras',\n",
    "    verbose = 2,\n",
    "    save_best_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4a4d9",
   "metadata": {},
   "source": [
    "## Early stopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9333526",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(\n",
    "    patience = 40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f56b4",
   "metadata": {},
   "source": [
    "## Learning rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80c30f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def scheduler(epoch,lr):\n",
    "    print(f'Learning rate: {lr}')\n",
    "    if epoch < 2:\n",
    "        return lr \n",
    "    else:\n",
    "        return lr * math.exp(-0.1) \n",
    "\n",
    "lr_scheduler_cb = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbe3e0",
   "metadata": {},
   "source": [
    "## TensorBoard callback for vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb66c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = TensorBoard('logs',update_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7102728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.0007408182718791068\n",
      "Epoch 1/100\n",
      "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0190\n",
      "Epoch 1: val_loss did not improve from 0.06547\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0195 - val_accuracy: 0.9810 - val_loss: 0.0729 - learning_rate: 7.4082e-04\n",
      "Learning rate: 0.0007408182718791068\n",
      "Epoch 2/100\n",
      "\u001b[1m1088/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0175"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_16545/3550847870.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.fit(\n\u001b[32m      2\u001b[39m     X_train,\n\u001b[32m      3\u001b[39m     y_train,\n\u001b[32m      4\u001b[39m     validation_data = (X_test,y_test),\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    374\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m    375\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m                     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m    377\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m                     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    380\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    381\u001b[39m \n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/callbacks/callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._async_train:\n\u001b[32m    170\u001b[39m             self._async_dispatch(self._on_train_batch_end, batch, logs)\n\u001b[32m    171\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m             self._on_train_batch_end(batch, logs)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/callbacks/callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    192\u001b[39m         logs = python_utils.pythonify_logs(logs)\n\u001b[32m    193\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;28;01min\u001b[39;00m self.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m             callback.on_train_batch_end(batch, logs=logs)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/callbacks/progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         self._update_progbar(batch, logs)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/callbacks/progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     91\u001b[39m         self._maybe_init_progbar()\n\u001b[32m     92\u001b[39m         self.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m             self.progbar.update(self.seen, list(logs.items()), finalize=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/utils/progbar.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m self._values_order:\n\u001b[32m    163\u001b[39m                 info += f\" - {k}:\"\n\u001b[32m    164\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._values[k], list):\n\u001b[32m    165\u001b[39m                     avg = backend.convert_to_numpy(\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m                         backend.numpy.mean(\n\u001b[32m    167\u001b[39m                             self._values[k][\u001b[32m0\u001b[39m] / max(\u001b[32m1\u001b[39m, self._values[k][\u001b[32m1\u001b[39m])\n\u001b[32m    168\u001b[39m                         )\n\u001b[32m    169\u001b[39m                     )\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis, keepdims)\u001b[39m\n\u001b[32m    712\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"int\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m ori_dtype \u001b[38;5;28;01mor\u001b[39;00m ori_dtype == \u001b[33m\"bool\"\u001b[39m:\n\u001b[32m    713\u001b[39m         result_dtype = compute_dtype\n\u001b[32m    714\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    715\u001b[39m         result_dtype = ori_dtype\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     output = tf.reduce_mean(\n\u001b[32m    717\u001b[39m         tf.cast(x, compute_dtype), axis=axis, keepdims=keepdims\n\u001b[32m    718\u001b[39m     )\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(output, result_dtype)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m     89\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m     91\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1261\u001b[39m \n\u001b[32m   1262\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1266\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2590\u001b[39m   \"\"\"\n\u001b[32m   2591\u001b[39m   keepdims = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(keepdims)\n\u001b[32m   2592\u001b[39m   return _may_reduce_to_scalar(\n\u001b[32m   2593\u001b[39m       keepdims, axis,\n\u001b[32m-> \u001b[39m\u001b[32m2594\u001b[39m       gen_math_ops.mean(\n\u001b[32m   2595\u001b[39m           input_tensor, _ReductionDims(input_tensor, axis), keepdims,\n\u001b[32m   2596\u001b[39m           name=name))\n",
      "\u001b[32m~/miniconda3/lib/python3.13/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input, axis, keep_dims, name)\u001b[39m\n\u001b[32m   6510\u001b[39m         _ctx, \u001b[33m\"Mean\"\u001b[39m, name, input, axis, \u001b[33m\"keep_dims\"\u001b[39m, keep_dims)\n\u001b[32m   6511\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6512\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   6513\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m6514\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   6515\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   6516\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   6517\u001b[39m       return mean_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data = (X_test,y_test),\n",
    "    epochs = 100,\n",
    "    callbacks = [model_checkpoint_cb,early_stopping_cb,lr_scheduler_cb,tensorboard_cb]\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4717888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nirzar-diwan/miniconda3/lib/python3.13/site-packages/tensorboard/default.py:30: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "2026-02-10 14:42:46.673254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.20.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857c932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
